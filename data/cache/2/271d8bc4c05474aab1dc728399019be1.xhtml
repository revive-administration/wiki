
<h1 class="sectionedit1" id="장_기초">1장 기초</h1>
<div class="level1">

</div>
<!-- EDIT1 SECTION "1장 기초" [1-26] -->
<h2 class="sectionedit2" id="요구사항">1-2 요구사항</h2>
<div class="level2">

</div>
<!-- EDIT2 SECTION "1-2 요구사항" [27-55] -->
<h3 class="sectionedit3" id="연결성">1.2.1 연결성</h3>
<div class="level3">

</div>

<h4 id="링크_노드_클라우드">링크, 노드 ,클라우드</h4>
<div class="level4">

<p>
네트워크 연결성은 다양한 단계에서 발생한다. 최저 단계의 네트워크는 동축 케이블이나 광섬유 등을 이용하고 두 대 이상의 컴퓨터가 직접 연결되어 이루어진다. 이러한 연결매체를 링크(link)라 하고, 이를 이용해 연결된 컴퓨터들은 노드(node)라고 한다. 교환망은 각 노드가 하나 이상의 점대점 링크에 연결되어 있는 노드들의 집합을 나타낸다. 두 개 이상의 링크에 연결되어 있는 노드는 데이터를 하나의 링크에서 다른 링크로 넘겨 주는 역할을 한다. 이 전달 노드들이 체계적으로 구성되어 교환망을 형성한다. 무수히 많은 교환망 중에 회선 교환기(circuit switch)와 패킷 교환기(packet switch)가 가장 일반적이다. 회선 교환기는 전화 시스템에 사용되고, 패킷 교환기는 대부분의 컴퓨터 네트워크에 사용되는데 이들은 이 책의 중점적인 내용이 될 것이다.
</p>

<p>
패킷 교환망은 일반적으로 저장-전달(store-and-forward)이라는 방법을 사용한다. 이름이 나타내는 것처럼, 저장-전달 네트워크의 각 노드는 우선 완전한 패킷을 받아서 내부 메모리에 저장한 후 다음 노드에 전달한다. 이와 반대로, 회선 교환망은 우선 링크들 사이에 전용회선을 만든 뒤, 보내는 노드가 이 회선을 통해 연속된 데이터 비트를 목적지 노드에 보낼 수 있도록 하는 것이다.
</p>

<p>
[그림 1.3]의 클라우드(cloud, 구름 모양)는 네트워크를 구성하는 내부 노드(이들은 공통적으로 스위치라고 하며, 패킷의 저장, 전달이 주된 기능이다)와 네트워크를 사용하는 클라우드 밖의 외부 노드(일반적으로 호스트라고 하며, 사용자 지원과 애플리케이션 프로그램 실행을 담당한다)를 구분한다. 이 클라우드는 어떤 종류의 네트워크라도 상관없이, 즉 단일 점대점 링크, 다중 접속 링크, 또는 교환망에 상관없이 네트워크를 표시하는 데 사용된다. 
</p>

<p>
두 개 이상의 네트워크에 연결된 노드는 공통적으로 라우터 또는 게이트웨이라 하는데 스위치와 거의 동일한 역할, 즉 메시지를 한 네트워크에서 다른 네트워크로 전달을 한다. 단지 호스트들이 서로 직간접으로 연결되어 있다고 해서 호스트 간 연결성을 제공하는 데 성공한 것은 아니다. 최종 요구사항은 각 노드가 통신을 원하는 네트워크 상의 다른 노드를 지정할 수 있어야 한다. 이 기능은 각 노드에 주소(address)를 할당함으로써 이루어진다. 주소는 노드를 나타내는 바이트 문자열(byte string)이다. 즉, 네트워크는 노드의 주소를 이용하여 다른 노드와 구분할 수 있게 된다. 보내는 노드(source node)가 목적지 노드(destination node)에 메시지를 보내고자 할 때는 목적지 노드의 주소를 지정한다. 발생지 노드와 목적지 노드가 서로 직접 연결되어 있다면 스위치와 라우터가 이 주소를 이용하여 어떻게 메시지를 목적지까지 전달할지를 결정한다. 이렇게 주소를 이용해 목적지 노드까지 메시지를 전달하는 방법을 체계적으로 결정하는 과정을 라우팅(routing)이라고 한다.
</p>

</div>
<!-- EDIT3 SECTION "1.2.1 연결성" [56-3502] -->
<h3 class="sectionedit4" id="비용_효율적_자원_공유">1.2.2 비용 효율적 자원 공유</h3>
<div class="level3">

<p>
호스트가 어떻게 네트워크를 공유하는가를 이해하기 위해서는 다중화(multiplexing), 즉 다중 사용자 간의 시스템 자원 공유를 의미하는 기초 개념을 도입해야 한다. 직관적으로 이해하면 다중화는 시분할(timesharing) 컴퓨터 시스템과 유사하게 설명될 수 있다. 즉, 단일 CPU가 다중 작업 간에 공유될 때(다중화될 때), 각각의 작업은 자신들만의 프로세서를 가지고 있다고 믿는 것처럼 이해할 수 있을 것이다. 이와 유사하게, 다중 사용자에 의해 보내진 데이터가 네트워크를 구성하는 물리적 링크 위에서 다중화될 수 있다.
</p>

<p>
다중 흐름을 하나의 물리적 링크 위에 다중화하는 데 여러가지 방법이 있다. 일반적으로 많이 쓰이는 한가지 방법은 STDM(Synchronous Time-Division Multiplexing)이다. STDM의 개념은 시간을 동일한 크기의 조각으로 나누어 라운드 로빈 방식으로 각각의 흐름에 데이터를 보낼 수 있는 기회를 주는 것이다. 또 다른 방법으로는 FDM(Frequency-Division Multiplexing)이 많이 사용된다. FDM은 서로 다른 주파수로 각각의 흐름을 전송하는데, 이는 각 TV 방속국이 물리적 케이블 TV 링크 위에 서로 다른 주파수를 이용하여 자사의 신호를 전송하는 것과 유사하다.
</p>

<p>
STDM과 FDM은 두 가지 제한점을 갖는다. 첫 번재, 흐름(두 개의 호스트)중 하나가 보낼 데이터를 가지고 있지 않다면, 이 흐름에 할당된 부분, 즉 시간 조각(quantum) 또는 주파수가 다른 흐름들 중 하나가 보낼 데이터를 가지고 있어도 유휴 상태로 있게 된다. 두 번째, STDM과 FDM 모두 최대 흐름수가 고정되고 사전에 알려져야 하는 상황에서만 사용할 수 있다. STDM의 경우에 시간 조각의 크기를 재조정하거나 추가로 시간 조각을 할당하는것이 실용적이지 않기 때문이다.
</p>

<p>
가장 많이 이용되는 다중화의 형태는 통계적 다중화(statistical multiplexing)이다. 비록 이름 자체로는 개념을 이해하는 데 그다지 도움이 되지 않지만, 통계적 다중화는 실제로 아주 간단한 두 가지 핵심 개념이 있다. 첫 번째, STDM의 경우처럼 물리적 링크가 시간적으로 공유된다. 즉, 한 흐름의 첫 번째 데이터가 물리적 링크를 따라 전송되고, 그 뒤에 다른 흐름의 데이터가 전송되고, 이와 같은 전송이 계속 된다. 그러나 STDM과는 달리 각 흐름으로부터의 데이터가 미리 정해진 시간에 따르지 않고 요구에 따라 전송된다. 그러므로 한 개의 흐름만이 데이터를 보내야 한다면, 자신의 시간 몫이 돌아올 때까지 기다리지 않고 즉시 전송할 수 있게 된다. 이렇게 유휴시간을 줄임으로써 패킷 교환의 효율성이 높아지게 된다.
</p>

<p>
그러나 통계적 다중화는 모든 흐름에게 자신이 전송할 수 있는 기회를 보장할 수 있는 방법이 없다. 즉 일단 하나의 흐름이 데이터를 보내기 시작함녀 다른 흐름에게 기회를 줄 수 있도록 전송을 제한할 수 있는 어떤 방법이 필요하다. 이 제한된 크기의 데이터 블록은 패킷이라 지칭되는데 애플리케이션 프로그램이 보낼 수 있는 임의의 크기를 갖는 메시지와 구분된다. 패킷 교환망의 최대 패킷 크기 제한은 호스탁 생성한 메시지를 한 패킷에 담아 보낼 수 없는 경우를 초래하기도 한다. 즉, 소스는 매시지를 여러개의 패킷으로 나누어 보내고, 받는 쪽에서 이들 패킷을 원래 메시지로 재조립해야 한다.
</p>

<p>
다시 말하면 각각의 흐름이 연속된 패킷을 물리적 연결을 통해 전송할 때 패킷만으로 다음에 전송될 패킷을 결정한다. 하나의 흐름만이 보낼 데이터를 가지고 있다면, 연속해서 자신의 패킷을 보낼 수도 있다. 그러나 하나 이상의 흐름이 데이터를 보내려고 한다면, 이 패킷들은 링크 위에 번갈아 보내진다. 
</p>

<p>
공유 링크에 어느 패킷을 언제 보내는가 하는 것은 다양한 방법으로 결정할 수 있다. 특정한 흐름에 대해 대역폭을 지정하도록 하는 네트워크를 QoS(Quality of Service)가 보장되었다고 한다.
</p>

<p>
또한 스위치가 세 개의 패킷 흐름을 하나의 링크로 다중화해야 하기 때문에 공유 링크의 용량보다 빠르게 패킷을 전달받을 수도 있다. 이런 경우에 스위치는 이들 패킷을 메모리 상에 버퍼링해야만 한다. 스위치가 내보낼 수 있는 것보다 빠르게 패킷이 들어오는 상황이 장시간 게속되면, 스위치의 버퍼 공간이 모자라 어떤 패킷은 버려야 할 것이다. 스위치가 이런 상태에서 운영되면 혼잡(congest)하다고 한다.
</p>

<p>
요컨대, 통계적 다중화는 다중 사용자에게 내트워크 자원(링크와 노드)을 좀더 세밀하게 공유하기 위한 비용 효율적인 방법을 정의한다. 이 방식은 패킷을 흐름의 단위로 정의하여 네트워크의 링크가 여러 흐름에 할당되며, 각 스위치가 연결되어 있는 물리적 링크의 사용 스케줄을 패킷별로 정할 수 있게 한다. 여러 흐름에 대한 링크 용량의 공평한 할당과 혼잡 발생시의 대응책이 통계적 다중화의 가장 큰 어려움이다.
</p>

</div>
<!-- EDIT4 SECTION "1.2.2 비용 효율적 자원 공유" [3503-9059] -->
<h3 class="sectionedit5" id="일반적인_서비스의_지원">1.2.3 일반적인 서비스의 지원</h3>
<div class="level3">

<p>
두 개의 애플리케이션이 서로 통신해야 할 때, 단순히 하나의 호스트에서 다른 호스트로 메시지를 보내는 것 이상의 복잡한 일이 일어나야 한다. 한 가지 방법은 애플리케이션 설계자들이 이런 모든 복잡한 기능을 각 애플리케이션 프로그램에 추가하는 것이다. 그런데, 많은 애플리케이션들이 공통된 서비스를 필요로 하기 때문에, 이런 공통 서비스를 한 번 구현하고 애플리케이션 설계자로 하여금 이런 공통 서비스 위에 애플리케이션을 만들도록 하는 것이 훨씬 더 바람직하다. 네트워크 설계자의 어려움은 공통된 서비스를 올바르게 찾아내는 것이다. 목표는 네트워크의 복잡함을 애플리케이션에게 보이지 않게 하며, 또한 애플리케이션 설계자를 지나치게 제한하지 않는 것이다.
</p>

<p>
직관적으로 보면, 네트워크란 애플리케이션 계층에서 프로세스가 서로 통신할 수 있는 논리적 채널을 제공하는 것이고, 각 채널은 애플리케이션에 의해 요구되는 서비스를 제공한다. 즉 클라우드가 컴퓨터 간의 연결성을 임의적으로 나타내기 위해 사용되는 것처럼, 채널은 하나의 프로세스를 다른 프로세스와 연결하는 것으로 생각할 수 있다. 그림 1.7은 일련의 호스트를 연결하는 클라우드 위해 구현된 논리적 채널 위에서 통신하는 애플리케이션 프로세스의 한 쌍을 나타낸다. 채널을 두 애플리케이션을 연결하는 파이프와 같이 생각하고, 보내는 애플리케이션은 파이프의 한쪽 끝에 데이터를 놓아 파이프의 반대쪽에 있는 애플리케이션에 전달되는 것으로 이해할 수 있다.
</p>

<p>
채널이 애플리케이션에 무슨 기는을 제공해야 하는가를 제대로 식별하는 것은 쉽지 않다. 일반적으로 네트워크는 다양한 종류의 채널을 제공하여 애플리케이션에 따라 요구사항을 가장 잘 충족하는 채널을 선택할 수 있게 해준다.
</p>

</div>

<h4 id="공통적인_통신_패턴의_확인">공통적인 통신 패턴의 확인</h4>
<div class="level4">

<p>
추상 채널을 설계하려면 먼저 대표적은 애플리케이션들의 통신 필요성을 이해하고, 이들의 공통된 통신 요구사항을 추출해 내고, 마지막으로 네트워크 안에 이런 요구사항을 충족시키는 기능을 포함하도록 해야 한다.
</p>

</div>

<h4 id="신뢰성">신뢰성</h4>
<div class="level4">

<p>
첫 번째로 고려할 사항은 컴퓨터 네트워크는 완벽하지 않다는 것이다. 기계들은 정지하고, 다시 부팅하고, 연결선이 끊어지고, 전기 장애가 전송 중인 데이터의 비트를 망가뜨린다. 그러므로 네트워크의 중요한 요구사항은 이런 종류의 고장 및 오류를 감추어 애플리케이션 프로그램이 그러한 부분을 다루지 않게 하는 것이다.
</p>

<p>
일반적으로 네트워크 설계자가 우려해야 할 세 가지 종류의 고장이 있다. 첫 번째, 패킷이 물리적 링크를 따라 전송될 때, 비트 오류가 데이터에 들어갈 수가 있다. 대체적으로 연속된 비트들이 망가지는 버스트 오류가 일어난다. 비트 오류는 대개 번개나 전압의 급상승, 마이크로웨이브 오븐과 같은 외부의 작용에 의해 데이터 전송이 방해를 받기 때문에 일어난다. 
</p>

<p>
두 번째, 고장이 비트가 아닌 패킷에서 일어나는 경우이다. 즉, 전채 패킷이 네트워크에 의해 사라져버리는 것이다. 이것이 발생하는 이유 중 하나는 패킷이 수정될 수 없는 비트 오류를 포함하고 있어서 버려야 하는 경우이다. 그러나 보다 흔한 이유는 패킷을 다루는 노드 중 하나에서 운영되는 소프트웨어(한 링크에서 다른 링크로 패킷을 전달하는 스위치)가 오류를 범하는 것으로, 잘못된 링크로 패킷을 전달해서 원하는 목적지에 전달되지 않는 것이다. 이보다 더 흔한 것은 전달 노드에서 용량 초과가 발생할 때 패킷을 저장할 공간이 부족해서 패킷을 버려야 할 경우이다. 드물게는 한 노드에서 실행되는 패킷을 전송하는 소프트웨어가 실수를 하는 경우이다.
</p>

<p>
세 번째, 노드와 링크 단계에서 고장이 일어나는 경우이다. 즉, 물리적 링크가 끊어지거나 연결된 컴퓨터가 정지하는 것이다. 세번째 고장 문제를 다루는 데 있어서 가장 어려운 점 중 하나는 고장난 컴퓨터와 단지 속도가 느린 컴퓨터를 구분하는 것과, 끊어진 링크와 연결이 좋지 않아 비트 오류를 많이 유발하는 링크를 구분하는 것이다.
</p>

</div>
<!-- EDIT5 SECTION "1.2.3 일반적인 서비스의 지원" [9060-13832] -->
<h2 class="sectionedit6" id="네트워크_구조">1-3 네트워크 구조</h2>
<div class="level2">

</div>
<!-- EDIT6 SECTION "1-3 네트워크 구조" [13833-13868] -->
<h3 class="sectionedit7" id="계층화와_프로토콜">1.3.1 계층화와 프로토콜</h3>
<div class="level3">

<p>
상위 계층에서 제공되는 서비스의 실행은 하위 계층에서 제공되는 서비스로 구현된다. 예를 들면, 네트워크란 그림에 나타낸 것처럼 애플리케이션 프로그램과 기반 하드웨어 사이에 두 개의 계층으로 구성된 것으로 상상할 수 있다 이 경우, 하드웨어 바로 위의 계층은 호스트 간의 연결성을 제공할 수 있는데, 이는 어떤 호스트 사이에는 복잡한 네트워크 토폴로지가 있을 수 있다는 사실을 이 계층 안에 포함하고 있다. 그 위의 계층은 사용 가능한 호스트 간 통신 서비스를 구축하여 프로세스 간 채널을 지원하는데, 이는 네트워크가 때때로 메시지를 잃어버릴 수 있다는 사실을 계층 안에 포함하고 있다.
</p>

<p>
계층화는 두 가지 좋은 특징을 제공한다. 첫 번째, 네트워크 구축 문제를 보다 다루기 쉽게 만들어 준다. 모든 일을 다 할 수 있는 하나의 소프트웨어를 실행하는 것보다는 각각의 계층이 한 부분씩 담당하게 하는 것이다. 두 번째, 계층화는 보다 모듈화된 설계를 제공한다. 신규 서비스를 제공하기를 원한 경우에는 한 계층의 기능만을 수정하고, 그 밖의 다른 계층들의 기능은 그대로 이용하면 된다. 
</p>

<p>
이제, 계층화를 이용하여 네트워크 구조를 더욱 정확히 논의할 준비가 되었다. 네트워크 시스템의 계층을 구성하는 추상적 객체를 프로토콜이라고 부른다. 즉, 프로토콜은 상위 단계의 객체(애플리케이션 프로세스 또는 상위 프로세스)가 메시지를 교환하기 위해 사용하는 통신 서비스를 제공한다. 예를 들면, 우리는 앞에서 토의되었던, 요구/응답과 메시지 흐름 채널에 해당하는 요구/응답 및 메시지 흐름 프로토콜을 생각해 볼 수 있다.
</p>

<p>
각 프로토콜은 두 개의 다른 인터페이스를 정의한다. 첫 번재, 프로토콜은 같은 컴퓨터 상에서 통신 서비스를 사용하려는 다른 객체에 대한 서비스 인터페이스(service interface)를 정의한다. 이 서비스 인터페이스는 지역 객체가 프로토콜을 이용해서 수행할 수 있는 작업을 정의한다. 예를 들어, 요구/응답 프로토콜은 애플리케이션이 메시지를 보내고 받을 수 있는 작업을 지원할 것이다.
</p>

<p>
두 번째, 프로토콜은 다른 기계의 동료(peer)에게 동료 인터페이스(peer interface)를 정의한다. 이 인터페이스는 통신 서비스를 실행하기 위해 프로토콜 동료 간에 교환된 메시지의 형태와 의미를 정의한다. 이것을 통해 한 기계의 요구/응답 프로토콜이 다른 기계의 동료 프로토콜과 통신하는 방법을 결정하게 된다. 예를 들어 HTTP의 경우를 살펴보면 프로토콜 사양은 어떻게 &#039;GET&#039; 명령어가 구성되어 있는지와, 어떤 인자가 명령어와 함께 사용될 수 있는지, 그리고 그러한 명령어를 웹 서버가 받았을 때 어떻게 응답하는지가 정의되어 있다.
</p>

<p>
요약하면 프로토콜은 지역적으로 내보내는 통신 서비스(서비스 인터페이스)와 이를 위해 동료 프로토콜과 교환하는 메시지(동료 인터페이스)를 관장하는 규칙들을 정의한다. 동료들이 링크를 통하여 서로 직접 통신하는 하드웨어 단계를 제외하고는 동료 간 통신은 간접적으로 이루어진다. 즉, 각 프로토콜은 하위 단계 프로토콜에게 메시지를 전달하고, 이 하위 프로토콜은 자신의 동료에게 메시지를 전달하여 각 동료들 간에 의사소통을 한다. 추가로 어느 단계에서나 다수의 프로토콜이 있을 수 있는데, 각 프로토콜은 각기 다른 통신 서비스를 제공한다.
</p>

<p>
프로토콜이라는 말은 두 가지 경우로 사용되는 것을 주목하자. 때로는 추상적 인터페이스를 의미하고(즉, 서비스 인터페이스에 의해 정의되는 작업과, 동료 프로세스 간에 교환되는 메시지의 형태와 의미), 때로는 이 두 인터페이스를 실제로 구현하는 모듈을 의미한다. 인터페이스와 이 인터페이스를 구현하는 모듈을 구분하기 위해, 전자를 일반적으로 프로토콜 사양(protocal specification)이라고 지칭한다.
</p>

</div>
<!-- EDIT7 SECTION "1.3.1 계층화와 프로토콜" [13869-18328] -->
<h3 class="sectionedit8" id="캡슐화">캡슐화</h3>
<div class="level3">

</div>
<!-- EDIT8 SECTION "캡슐화" [18329-18350] -->
<h3 class="sectionedit9" id="다중화와_역다중화">다중화와 역다중화</h3>
<div class="level3">

<p>
패킷 교환의 기본 아이디어는 하나의 물리적 링크 위에 다수의 데이터 흐름으로 다중화한다는 것을 기억하자. 똑같은 아이디어가 스위칭 노드뿐만 아니라 프로토콜 그래프에 적용된다. 예를 들면, RRP를 논리적은 통신 채널의 구현으로 생각할 수 있는데, 두 개의 다른 애플리케이션으로부터 전달된 메시지들은 발생지 호스트에서 다중화되어 목적지 호스트로 전달되고 이는 다중화되어 적합한 애플리케이션에게 전달된다.
</p>

<p>
실제로 이것이 의미하는 것은 RRP가 메시지에 첨가하는 헤더는 메시지가 속하는 애플리케이션을 나타내는 식별자를 포함하고 있다. 이 식별 결과는 RRP의 역다중화 키(demultiplexing key), 또는 줄여서 demux key라고 한다. 발생지 호스트에서 RRP는 적합한 역다중화 키를 헤더에 포함시킨다. 메시지가 목적지 호스트의 RRP에 도착했을 때, RRP는 이 헤더를 잘라내고 역다중화 키를 검사하여 메시지를 올바른 애플리케이션에 전달한다.
</p>

</div>
<!-- EDIT9 SECTION "다중화와 역다중화" [18351-19508] -->
<h2 class="sectionedit10" id="osi_구조">1.3.2 OSI 구조</h2>
<div class="level2">

<p>
…24P
</p>

</div>
<!-- EDIT10 SECTION "1.3.2 OSI 구조" [19509-19545] -->
<h2 class="sectionedit11" id="성능">1-5 성능</h2>
<div class="level2">

</div>
<!-- EDIT11 SECTION "1-5 성능" [19546-19568] -->
<h3 class="sectionedit12" id="대역폭과_소요시간">1.5.1 대역폭과 소요시간</h3>
<div class="level3">

<p>
네트워크 성능은 두 가지 기본적인 인자로 측정된다. 각각은 대역폭(처리량이라고 한다)과 소요시간(지연시간이라고도 한다)이다. 네트워크의 대역폭은 일정 시간 동안 네트워크로 전송될 수 있는 비트 수에 의해 결정된다. 
</p>

<p>
두 번째, 성능 측정 인자인 소요시간(latency)은 단일 비트가 네트워크의 한 쪽에서 다른 쪽으로 이동하는 데 걸리는 시간을 말한다(대역폭과 마찬가지로, 단일 링크 또는 채널 단위로 소요시간을 생각할 수 있다). 소요시간은 전적으로 시간에 의해 측정된다. 예를 ㄷ르어 대륙 간 네트워크가 24밀리초(ms)의 소요시간을 가진다면, 이는 대륙의 한 쪽 끝에서 다른 쪽 끝으로 한 비트를 보내는 데 24ms가 걸린다는 것이다. 그러나 편도 소요시간보다는 네트워크를 왕복하는 데 걸리는 소요시간이 더 중요한 상황이 많이 있다. 이것을 네트워크의 왕복 지연시간(Rount-Trip Time, RTT)이라고 한다.
</p>

<p>
소요시간은 세 부분으로 나누어 생각할 수 있다. 첫 번째, 전파지연이 있다. 이 지연은 통신선 위의 비트를 포함해서 광속보다 빠르게 이동할 수 있는 것은 아무것도 없기 때문에 생긴다. 두 지점의 거리를 알고 있다면, 빛의 전파시간을 계산할 수 있는데 빛은 매체에 따라 다른 속도로 전파된다는 것을 유의해야 한다. 두 번재, 단위 데이터를 전송하는데 걸리는 시간이다. 이것은 네트워크 대역폭과 데이터를 전송하는 패킷 크기에 따라 계산되는 값이다. 세 번째, 1.2.2절에서 논의된 것처럼 패킷 교환기가 외부 링크로 패킷을 전달하기 전에 얼마 동안 저장해야 되기 때문에 네트워크 내부에서 큐잉(queuing) 지연이 있을 수 있다. 그러므로 거리는 데이터가 이동할 전송선로의 길이라 하고 광속은 전송선로에서의 실제적인 빛의 속도, 크기는 패킷의 크기, 그리고 대역폭은 패킷이 전송되는 전송선로에서의 대역폭이라 할 때, 다음과 같이 총 소요시간을 정의할 수 있다.ㅇ
</p>
<ul>
<li class="level1"><div class="li"> 소요시간 = 전파시간 + 전송시간 + 큐잉시간</div>
</li>
<li class="level1"><div class="li"> 전파시간 = 거리/광속</div>
</li>
<li class="level1"><div class="li"> 전송시간 = 크기/대역폭</div>
</li>
</ul>

<p>
기억해야 할 것은 실제의 네트워크와 달리, 메시지에는 오직 한 비트의 정보만 들어 있고, 단일 링크에서 작동하는 환경이라면 전송 시간과 큐잉 시간은 문제가 되지 않고, 소요시간은 단지 전파시간에만 영향을 받는다는 것이다.
</p>

<p>
이 책에서는 메시지가 전달되거나 객체가 움직이는 것과 같은 기능을 수행하는 데 걸리는 시간을 나타내기 위해서 소요시간(latency)과 지연시간(delay)을 일반적인 의미로 사용하고 있다. 링크의 한 쪽에서 다른 쪽으로 신호를 전파하는 데 걸리는 시간을 나타낼 때 전파지연 이라고 한다. 
</p>

</div>
<!-- EDIT12 SECTION "1.5.1 대역폭과 소요시간" [19569-22652] -->
<h3 class="sectionedit13" id="지연시간_x_대역폭_곱">1.5.2 지연시간 x 대역폭 곱</h3>
<div class="level3">

<p>
지연시간 x 대역폭 곱이라 하는 두 측정 기준의 곱을 논의하는 것이 또한 유용하다. 직관적으로 한 쌍의 프로세스 간의 채널을 속 빈 파이프로 생각하면 지연시간은 파이프의 길이와 같고 대역폭은 파이프의 지름으로 이해한다면, 지연시간 x 대역폭 곱은 파이프의 부피(어느 시점에 파이프를 통해 보낼 수 있는 최대 비트 수)로 생각할 수 있다. 다시 말해서, 지연시간(시간으로 측정)이 파이프의 길이와 같다면, 주어진 각 비트의 너비(역시 시간으로 측정)를 가지고 파이프에 담을 수 있는 비트 수를 계산할 수 있다. 
</p>

</div>
<!-- EDIT13 SECTION "1.5.2 지연시간 x 대역폭 곱" [22653-] -->
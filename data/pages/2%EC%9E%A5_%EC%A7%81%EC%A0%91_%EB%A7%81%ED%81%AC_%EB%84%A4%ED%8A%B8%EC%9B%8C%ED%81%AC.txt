====== 2장 직접 링크 네트워크 ======
===== 2-1 하드웨어 구축 요소 =====
네트워크는 노드(node)와 링크(link)라는 두 종류의 구축 요소에 의하여 구성된다. 이 사실은 점대점 링크가 두 노드를 연결하는 가장 간단한 네트워크에서부터 전세계에 걸친 인터넷에 이르기까지 마찬가지로 적용된다. 
==== 2.1.1 노드 ====
노드는 종종 탁상 워크스테이션, 멀티프로세서 또는 PC와 같은 범용 컴퓨터가 된다. 사용자가 애플리케이션 프로그램을 수행시키는 호스트로 동작할 수 있으며, 네트워크 내부에서 하나의 링크로부터의 메시지를 다른 링크로 중계하는 교환기로 사용되거나, 또는 한 네트워크로부터의 인터넷 패킷을 다른 네트워크로 중계하는 라우터로 구성될 수 있다. 호스트가 아닌 네트워크 내부 교환기나 라우터를 주로 의미하는 네트워크 노드는 경우에 따라 특수 목적 하드웨어로 구현된다. 이와 같은 구현은 대개 성능 때문에 이루어진다. 즉, 특정 기능을 범용 프로세서보다 빨리 수행하는 주문형 하드웨어를 제작하는 것이 일반적으로 가능하기 때문이다. 

워크스테이션의 네트워크 어댑터(network adaptor)는 워크스테이션의 나머지 부분과 링크를 연결한다. 단순히 물리적인 연결만이 아니라 노드와 링크 사이에서 자기 자신의 프로세서를 갖는 능동적인 중계자 역할을 한다.

네트워크 어댑터는 두 개의 주요 구성 요소로 이루어진다고 생각할 수 있다. 호스트와 어떻게 통신할 것인지를 담당하는 버스 인터페이스와, 네트워크와 정확한 프로토콜로 통신할 수 있는 링크 인터페이스가 그것이다. 또한 이 구성 요소 사이에도 들어오고 나가는 데이터가 통과할 통신 경로가 있어야 한다.

다른 종류의 링크는 매우 다른 링크 인터페이스를 갖는 네트워크 어댑터를 요구한다. 대개의 경우, 어댑터는 CPU가 읽고 쓸 수 있는 제어상태 레지스터를 공시하고 있다. CSR(제어상태 레지스터)은 대개 메모리의 어떤 주소에 위치하며, 따라서 다른 메모리 주소와 똑같이 CPU를 읽고 쓰는 것이 가능하다. 호스트에서 동작하는 소프트웨어 모듈, 즉 디바이스 드라이버는 프레임을 보내고 또는 받는 명령을 CSR에 쓰고, 어댑터의 현재 상태를 알기 위해 CSR을 읽는다. 호스트에게 프레임의 수신과 같은 비동기적 이벤트를 알리기 위해 어댑터는 호스트에게 인터럽트를 건다.

네트워크 어댑터의 설계에서 가장 중요한 문제는 하나의 어탭터와 호스트의 메모리 사이에서 어떻게 프레임의 바이트를 이동시키는가이다. 직접 메모리 접근(Direct Memory Access, DMA)와 프로그램 I/O(Programmed I/O, PIO)라는 두 가지 기본적인 방법이 있다. DMA의 경우, 어댑터는 CPU의 참여 없이 호스트의 메모리를 직접 읽고 쓴다. 호스트는 어댑터에게 단지 메모리의 주소만을 주며, 어댑터는 이곳에 읽고 쓰기를 한다. PIO의 경우, 호스트의 CPU가 직접 메모리와 어댑터 사이의 데이터 이동을 책인진다. 프레임을 전송하기 위해서는 순환문을 돌면서 호스트의 메모리에서 하나의 워드를 읽고 이를 어댑터에 쓰는 것을 반복한다. 프레임을 수신할 때는 CPU가 어댑터로부터 워드를 읽어 오고 이를 호스트 메모리에 쓴다.

==== 2.1.2 링크 ====
네트워크 링크는 꼬인선, 동축케이블, 광섬유, 공간등과 같은 물리적 매체에 의하여 구현된다. 어떤 물리적 매체가 사용되더라도 이는 신호를 전달하는 데 사용된다. 신호들은 실제로는 빛의 속도로 이동하는 전자기파이다. 전자기파의 중요한 특성 중의 하나는 파가 진동하는 정도를 Hz 단위로 측정하는 주파수(frequency)이다. 파동에서 인접한 한 쌍의 최고점들 또는 최저점들 사이의 거리를 그 파동의 파장(wavelength)이라 부르며, 대개 미터 단위로 측정된다. 모든 전자기파가 빛의 속도로 이동하기 때문에, 빛의 속도를 파동의 주파수로 나누면 해당 파동의 파장과 같다. 

지금까지 설명에 따르면, 링크는 전자기파 형태의 신호를 반송하는 물리적 매체라고 할 수 있다. 이러한 링크는 우리가 관심을 가지고 전송하려는 이진 데이터를 포함하여 모든 종류의 정보를 전송하는 기반을 제공한다. 이때 이진 데이터(즉, 0과 1들)를 포함하여 모든 종류의 정보를 전송하는 기반을 제공한다. 이때 이진 데이터가 신호에 인코드(encode)되어 있다고 한다. 이진 데이터를 전자기파로 인코드하는 문제는 복잡한 주제이다. 이 주제를 보다 다루기 쉽게 하기 위해, 두 계층으로 나누어서 생각해 보기로 한다. 하위 계층은 신호의 주파수, 신호 크기 또는 위상을 변화시켜서 정보의 전송효과를 얻는 모듈레이션(modulation)을 담당한다. 모듈레이션의 간단한 예는 신호 파장의 출력(크기)을 변화시키는 것이다.

링크의 다른 속성은 정해진 시간 안에 얼마나 많은 비트 스트림을 인코드할 수 있는가이다. 하나의 전송매체만 사용할 수 있다면 링크에 연결된 노드는 전송매체를 공유하여야만 한다. 그러나 점대점 링크에서는 각각의 방향으로 두 개의 비트 스트림이 동시에 링크로 전송될 수 있는 경우가 자주 있다. 이와 같은 링크를 전이중(full-duplex)이라 한다. 어느 순간 한 방향으로만 데이터가 흐르도록 하면 반이중(half-duplex)이라 하는데, 이 경우 링크에 접속된 두 노드가 교대로 링크를 사용해야 한다.

=== 케이블 ===
노드가 같은 방, 같은 빌딩 또는 같은 사이트에 있다면, 케이블 여러 개를 사서 노드 사이를 물리적으로 직접 연결할 수 있다. 

=== 전용선 ===
=== 일반 가입자용 링크 ===
첫 번째 방법은 기존 전화 서비스(POTS)를 통해 모뎀을 사용하는 방법이다. 그러나 이 기술은 이미 대역폭의 한계에 도달햇기 때문에, 두 번째 방법인 ISDN(Integrated Services Digital Network)이 필요하게 되었다. 현재로서는 새로운 두 개의 기술이 ISDN을 추월한 상태라고 할 수 있는데, xDSL(Digital Subscriber Line)과 케이블 모뎀이 그들이다. xDSL은 거의 모든 집까지 들어와 있는 전화선을 통해 고속으로 데이터를 전송할 수 있는 기술을 통칭해서 나타낸다. ADSL은 가입자로부터 집중국 까지와, 집중국에서 가입자까지에 서로 다른 대역폭을 제공한다. 

=== 무선 링크 ===
무선 링크는 공간 또는 진공을 통해 라디오, 초단파, 또는 가시광선과 같은 전자기파를 전송한다. 

===== 2-2 인코딩(NRZ, NRZI, Manchester, 4B/5B)=====
노드와 링크를 유용한 구축 요소로 바꾸는 첫 번째 단계는 비트가 한 노드에서 다른 노드로 전송될 수 있도록 어떻게 이들을 연결하는가를 이해하는 것이다. 신호는 물리적 링크를 통해 전파된다. 따라서 임무는 발신지 노드가 보내고자 하는 이진 데이터를 링크가 운송할 수 있는 신호로 인코드하는 일과, 수신 노드에서 신호를 해당 이진 데이터로 다시 디코드하는 일이다. 변조(modulation)에 관한 자세한 사항은 무시하기로 하며, 고신호와 저신호라는 두 개의 이산 신호를 다룬다고 가정하자. 실제로는 이 신호는 구리 ㅟ주의 링크에서의 두 개의 다른 전압, 광링크에서는 두 개의 다른 전력 수준에 해당된다. 

이 장에서 논의되는 대부분의 기능은 노드를 링크와 연결하는 작은 하드웨어 장치인 네트워크 어댑터에 의하여 수행된다. 네트워크 어댑터는실제적으로 송신 노드에서 비트를 신호로 인코딩하며, 수신 노드에서 신호를 비트로 디코딩하는 신호 부품을 포함하고 있다. 신호는 두 신호 부품 사이의 링크를 통과하며, 비트는 네트워크 어댑터 사이를 흐른다.

다시 비트를 신호로 인코딩하는 문제를 살펴보자. 당연히 생각할 수 있는 방법은 데이터값 1은 고신호로, 데이터값 0은 저신호로 대응시키는 일이다. 이것이 정확히 NRZ(Non-Return to Zero)라 하는 인코딩 방식이 사용하는 방법이다. NRZ의 문제점은 여러 개의 1이 연속되는 경우, 신호가 오랜 기간 동안 고위에서 지속되며, 마찬가지로 0이 연속되는 경우 신호가 저위에서 지속된다는 점이다. 이와 같은 1또는 0의 연속은 두 개의 근본적인 문제점을 야기한다. 첫 번째, 기준값 혼돈(baeline wander)이라고 알려진 상황을 일으킨다. 구체적으로 설명하면, 수신자는 지금까지 받은 신호들의 평균을 유지해서 신호의 고저를 구분하는 데 사용한다. 신호가 이 평균보다 확실히 낮으면 수신자는 0을 받은 것으로 결정한다. 마찬가지로 신호가 평균보다 확실히 높으면 1로 해석한다. 물론 문제는 1또는 0이 너무 많이 연속해서 이어지면 이 평균이 변하게 되고, 이에 따라 신호의 확실한 변화를 감지하기가 어려워진다는 점이다.

두 번째 문제는 고위로부터 저위로, 또는 그 반대로 자주 전이하는 것은 다음에 설명할 클럭 복구(clock recovery)를 하는 데 필수적이라는 것이다. 직관적으로 설명하면, 클럭복구 문제란 인코딩과 디코딩 과정 모두가 클럭에 의하여 구동된다는 점에서 시작한다. 즉, 매 클럭 사이클(clock cycle)마다 송신자는 한 비트를 신호로 전송하고, 수신자는 한 비트를 신호로부터 복구한다. 수신자가 송신자가 전송하는 비트를 그대로 북구하기 위해서는 송신자와 수신자의 클럭이 정확히 동기화되어야만 한다. 수신자의 클럭이 송신자의 클럭보다 조금이라도 빠르거나 느리게 되면, 신호를 정확하게 디코드하지 못한다. 클럭을 별도의 선을 이용하여 수신자에게 보내는 것을 상상할 수 잇지만, 대개는 고려되지 않고 있다. 대신에 수신자가 수신한 신호로부터 클럭을 유도해 내도록 하는 클럭 복구 기법이 사용된다. 0에서 1로 또는 1에서 0으로의 전이와 같이, 신호가 바뀔 때마다 수신자는 그 시점이 클럭 사이의 경계라는 것을 알 수 있으며 이를 이용하여 자신의 클럭을 동기화시킬 수 있다. 그러나 오랫동안 신호 전이가 없으면, 클럭이 어긋나게 된다. 따라서 클럭 복구는 어떤 데이터가 보내지는가에 관계없이 신호에 많은 전이가 있는가에 의존한다.

이 문제를 해결하는 한 방법으로, NRZI(Non-Return to Zero Invert)라 하는 방식은 송신자가 1을 인코드할 때는 현재의 신호로부터 전이를 하고, 0을 인코드할 때는 현재의 신호를 유지한다. 이 방식은 1이 연속되는 문제는 해결하지만 0이 연속되는 경우는 아무 효과가 없다. 맨체스터 인코딩이라 하는 다른 방식은 NRZ 방식으로 인코드도니 데이터와 클럭을 배타적 논리합하여 전송함으로써 클럭과 신호를 합치는 일을 보다 명확히 한다. 

맨체스터 인코딩 방식의 문제점은 링크에서 신호 전이가 일어나는 비율이 두 배가 되면, 결국 수신자가 신호의 각 펄스를 인지하여야 하는 시간이 반으로 짧아지게 된다. 이와 같이 신호가 변화하는 비율을 링크의 변조속도(baud rate)라 한다. 

===== 2-3 프레이밍 =====
우리가 초점을 맞추고 있는 패킷 교환망에서는, 비트 스트림이 아닌 데이터의 블록(이 단게에서는 프레임이라 한다)이 노드 사이에서 교환된다. 노드가 프레임을 교환할 수 있도록 해주는 것은 네트워크 어댑터이다. 노드 A가 한 프레임을 노드 B로 전송하려 할 때, 노드는 자신이 어댑터에게 메모리부터 프레임을 전송하라고 명령한다. 이 결과로 비트의 연속이 링크로 보내지게 된다. 노드 B의 어댑터는 링크로부터 도착하는 비트의 연속을 함께 모아서 B의 메모리에 있는 해당 프레임에 넣는다. 정확히 어떤 비트가 한 프레임을 형성하는지, 다시 말해 어디서 프레임이 시작하고 끝나는지를 알아내는 것이 어댑터가 해결해야 할 중요 문제가 된다.

==== 2.3.1 바이트 중심 프로토콜 ====
프레이밍에서 가장 오래된 접근 방법 중의 하나는 터미널과 메인프레임을 연결하는 데서부터 유래한 것으로, 각 프레임을 비트의 묶음이 아닌 바이트의 묶음으로 간주하는 방법이다.
=== 보초 방법 ===
아래 그림은 BISYNC 플토콜의 프레임 형식을 보여 주고 있다. 패킷은 이름이 붙은 필드의 연속으로 볼 수 있다. 각 필드 위에는 해당 필드의 길이를 비트로 나타내는 숫자가 붙게 된다. 

BISYNC는 어디서 프레임이 시작하고 끝나는지를 표시하기 위해 보초 문자(sentinel charcter)라 불리는 특수 문자를 사용한다. 프레임의 시작은 특수한 SYN(synchronization) 문자를 보내는 것으로 표시된다. 다음으로 프레임의 데이터 부분은 두 개의 특수 보초 문자, STX(START OF TEXT), ETX(End Of Text) 사이에 둘러싸이게 된다. SOH(Start Of Header)는 STX 필드와 같은 목적으로 사용된다. 보초 방법의 문제점은 프레임의 데이터 부분에 ETX 문자가 나올 수도 있다는 것이다. BISTNC는 이 문제를 프레임의 몸체에 ETX 문자가 나올 때마다. 그 앞에 DLE 문자를 부이는 '확장(escaping)'방법으로 해결하였다. 프레임 내부에 나오는 DLE 문자도 또 다른 DLE 문자를 앞에 붙여 확장된다. 추가의 문자를 프레임의 데이터 부분에 삽입하기 대문에 이 같은 방법을 흔히 문자삽입이라고 부른다.

두 프레임 형식 모두 전송 오류를 감지하는 데 사용하는 순회 중복 검사(Cyclic Redundancy Check, CRC)라는 필드를 포함하고 있다. 이와 관련된 다양한 오류 검출 알고리즘은 다음에 설명할 것이다. 끝으로 프레임은 추가 헤더 정보를 위한 여유 공간을 포함하고 있다. 이 추가 헤더 정보는 다른 임무와 함께 링크 수준에서의 신뢰성 있는 전달 알고리즘에 사용된다.

보다 최근에 개발되어 전화 모뎀 링크에서 흔히 사용되는 PPP(Point-to-Point Protocol)는 문자 삽입을 사용하고 있다는 점에서 BISYNC와 유사하다.

그림에서 Flag 필드로 표시된 텍스트 시작을 나타내는 특수문자는 01111110이다. Address와 Control 필드는 대개 디폴트값을 가지므로 여기서는 설명하지 않기로 한다. Protocol 필드는 역다중화에 사용되며, IP나 IPX(노벨에 의해 개발된 IP와 유사한 프로토콜) 같은 상위 수준 프로토콜을 식별한다. 프레임의 페이로드 길이는 협상이 가능하지만, 디폴트값은 1500바이트이다. Checksum 필드는 2또는 4바이트이며, 2가 디폴트이다.

PPP 프레임 형식은 몇몇 필드의 길이들이 고정되어 있지 않고 협상에 의하여 조절된다는 점에서 독특하다. 이 협상은 LCP(Link Contrl Protocol)라고 불리는 프로토콜에 의하여 수행된다. PPP와 LCP는 나란히 동작한다. LCP는 제어 메시지를 PPP 프레임으로 포장하여 보내지는데, 이때 PPP 프레임의 Protocol 필드는 LCP 식별자를 가지게 된다. LCP는 이들 제어 메시지 안에 들어 있는 정보를 토대로 PP의 프레임 형식을 조정한다. 또한 LCP는 통신 양쪽이 반송 신호를 감지했을 때(예를 들어, 광수신기가 연결된 광케이블로부터 신호가 들어오는 것을 감지하였을 때), 둘 사이에 링크를 설정하는 작업도 담당한다.

**어떤 기능이 어떤 계층에 포함되어야 하는가?**

=== 바이트 수 방법 ===
보초값으로 파일의 끝을 알아내는 것의 댇안은 파일에 있는 내용의 개수를 파일의 앞에 포함시키는 방법이다. 프레이밍에서도 마찬가지이다. 프레임에 포함된 바이트 수를 프레임 헤더의 한 필드로 포함시킬 수 있다. DECNET의 DDCMP 프로토콜이 그림에 나타낸 바와 같이 이 방법을 쓰고 있다. 이 예에서 COUNT 필드는 프레임 몸체에 포함되어 있는  바이트 개수를 규정하고 있다.

이 방법의 한 가지 위험은 전송 오류가 COUNT 필드를 변질시킬 수 있으며, 이 경우 프레임의 끝을 올바르게 알아낼 수 없게 된다는 점이다. (보초 방법에서도 ETX 필드가 변질되면 유사한 문제가 발생한다.) 이 상황이 발생하면, 수신자는 잘못된 COUNT 필드가 나타내는 바이트만큼을 수신하고, 오류 감지 필드를 사용하여 프레임이 잘못되었다는 것을 결정하게 된다. 이것을 때로 프레이밍 오류(framing error)라 한다. 수신자는 다음 SYN 문자가 올 때까지 기다린 후, 새로운 프레임을 구성하는 바이트를 모으기 시작한다. 따라서, 하나의 프레이밍 오류가 연이어 프레임이 부정확하게 수신되도록 만들 수도 있다.

==== 2.3.2 비트 중심 프로토콜 ====
위에서 살펴본 바이트 중심 프로토콜과 달리, 비트 중심 프로토콜은 바이트의 경계는 고려하지 않는다. 즉, 프레임을 단순히 비트의 묶음으로 간주한다. 이 비트는 ASCII와 같은 문자로부터 나올 수도 있고, 영상의 픽셀 값, 또는 수행 파일의 명령어 또는 피연산자가 될 수도 있다. IBM이 개발한 SDLC(Synchronous Data Link Control)프로토콜은 비트 중심 프로토콜의 예이다. SLDC는 뒤에 ISO에 의하여 HDLC(High-Level Data Link Control) 프로토콜로 표준화되었다. 

HDLC는 프레임의 시작과 끝 모두를 특정한 비트 순서인 01111110으로 나타낸다. 이 비트 순서는 링크가 유휴 상태일 때 송신자와 수신자가 클럭을 동기화하기 위해서도 교환된다. 이 경우, 양쪽 프로토콜이 본질적으로 보초 방식을 사용한다. 한편, 이 특정 순서가 프레임 몸체의 어떤 곳에서도, 특히 바이트의 경계가 아닌 곳에서도 나올 수 있으므로, 비트 중심 프로토콜도 바이트 중심 프로토콜의 DLE 문자와 유사한 방법을 사용하는데, 이 방법을 비트 삽입(bit stuffing)이라 한다.

HDLC 프로토콜에서 비트 삽입은 다음과 같이 이루어진다. 송신자가 메시지에서 5개의 1을 연속하여 보낸 경우(즉, 의도적으로 01111110을 보내는 경우를 제외한 모든 경우)에는 다음 비트를 보내기 전에 하나의 0을 삽입하여 전송한다. 

보초값의 확장과 비트 삽입 방법 모두에 해당하는 한 가지 흥미로운 특징은 프레임의 길이가 프레임 내부의 페이로드(payload)로 전송되는 데이터에 의하여 결정된다는 점이다. 어떤 프레임에 전송되는 데이터는 임의의 내용이 될 수 있으므로, 모든 프레임을 같은 크기로 만드는 것은 사실상 불가능하다.

==== 2.3.3 클럭 기반 프레이밍 ====
프레이밍에 대한 세 번째 접근 방법은 SONET(Synchronous Optical Network) 표준에서 그 예를 볼 수 있다. 넓게 통용되는 일반적인 용어가 없기 때문에 이 방법은 클럭 기반 프레이밍(clock-based framing)이라고 한다. SONET은 벨 통신 연구소(Bellcore)에서 처음 제안되었으며, ANSI(American National Standards Institute)에 ㅇ의하여 광섬유를 통한 디지털 전송을 위해 개발되었으며, ITU-T에 의하여 채택되었다. SONET은 전화 회사들이 광섬유 네트워크를 통해 어떻게 데이터를 전송하는가를 정의하고 있다 SONET은 프레이밍과 인코딩 문제 모두를 다룬다. 또한 전화 회사에서는 매우 중요한 문제, 즉 여러 저속 링크를 하나의 고속 링크로 다중화하는 문제도 다루고 있다. 여기서는 프레이밍을 먼저 다루며, 다른 내용은 이어서 논의하도록 한다.

앞의 프레이밍 방법에서 논의한 바와 같이, 하나의 SONET 프레임은 수신자에게 어디서 프레임이 시작되고 끝나는지를 알려 주는 특별한 정보를 포함하고 있다. 그러나 유사점은 이것뿐이다. 우선, 비트삽입은 사용하지 않으며, 따라서 프레임의 길이는 전송되는 데이터에 좌우되지 않는다. 어떻게 수신자가 프레임의 시작과 끝을 알아내는가를 설명하기 위해, SONET 링크 중 가장 저속이며 STS-1로 알려진 51.84Mbps 링크를 살펴보도록 한다. STS-1의 프레임은 아래 그림과 같다. 프레임은 각각이 90바이트인 9개의 행으로 배열되어 있으며, 각 행의 처음 3바이트는 오버헤드, 나머지는 링크를 통해 전송되는 데이터가 사용한다. 프레임의 처음 2바이트는 특정 비트 양식(pattern)을 포함하며, 바로 이것이 수신자가 프레임의 시작점을 알아내는 것을 가능하게 한다. 그러나 비트 삽입을 사용하지 않기 때문에 이 비트 패턴이 프레임의 페이로드 부분에서도 나올 수 있다. 이 문제에 대비하기 위해 수신자는 특정 비트 패턴을 일정하게 검사한다. 즉, 각 프레임이 9x90=810바이트이므로 810 바이트마다 한 번씩 나오는지를 검사한다. 특정 패턴이 시간적으로 정확한 위치에서 나오게 되면, 수신자는 동기화가 이루어진 상태이며 프레임을 정확히 해석하였다고 판단할 수가 있다.

SONET은 복합하기 때문에 다른 부하 바이트의 구체적인 용도에 관한 것은 설명하지 않기로 한다. SONET이 복잡한 원인의 일부분은 SONET이 하나의 링크 위가 아닌 통신업자(carrier)의 광네트워크 위에서 동작하기 때문이라고 할 수 있다.(네트워크를 구현하는 것은 통신업자이며, 우리는 이들로부터 전용선을 임대하고 이를 링크로 사용하여 패킷 교환망을 구성하는 일에만 초점을 맞추고 있다는 사실을 기억하기 바란다.) 다른 원인은 SONET이 단순한 데이터 전송보다 훨씬 풍부한 서비스를 제공하기 때문이다. 예를 들어 SONET 링크의 용량 중 64Kbps는 관리에 사용되는 음성 채널로 따로 예약되어 있다.

SONET 프레임의 각 바이트는, 앞 절에서 설명한 1은 고위, 0은 저위로 하는 간단한 인코딩 방법인 NRZ를 사용하여 인코딩된다. 그러나 수신자의 클럭을 복구할 수 있는 충분한 전이가 있도록 하기 위해, 페이로드 바이트는 스크램블(scramble)된다. 스크램블은 전송할 데이터와 알려진 비트 패턴을 사용하여 배타적 논리합(XOR)을 계산함으로써 수행도니다. 길이가 127비트인 이 비트 패턴은 1에서 0으로의 전이를 많이 갖고 있어서, 이것을 전송할 데이터와 XOR하면 클럭을 복구하기에 충분한 전이를 갖는 신호가 생겨날 가능성이 높게 된다.

SONET은 여러 저속 링크의 다중화를 다음과 같이 지원한다. 하나의 SONET 링크는 51.84Mbps에서부터 2488.32Mbps 및 그 이상의 범위를 갖는 전송률의 유한한 집합 중 하나로 동작한다. 이들 비율이 모두 STS-1의 정수배라는 점을 유의해야 한다. 이와 같은 프레이밍의 특징은 하나의 SONET 프레임이 여러 개의 저속 비율 채널의 부 프레임을 포함할 수 있다는 점이다. 두 번째 관련된 특징은 각 프레임이 125msㅡ이 길이를 갖는다는 점이다. 즉, STS-1 비율에서는 하나의 SONET 프레임이 810바이트이며, STS-3 비율에서는 2430바이트가 하나의 SONET 프레임이다. 

직관적으로, STS-N 프레임은 N개의 STS-1프레임으로 구성된다고 생각할 수 있다. 여기서 프레임의 바이트는 인터리빙(interleaving) 된다. 즉, 첫 번째 프레임의 바이트가 전송되고, 다음은 두 번째 프레임의 바이트, 이하 같은 차례로 전송된다. 각 STS-N ㅍ레임의 바이트를 인터리빙하는 이유는 각각의 STS-1 프레임이 같은 속도로 진행되도록 하기 위해서이다. 즉, 모든 데이터가 수신자에게 125ms의 1/N 사이에 도착하지말고, 완만한 51Mbps의 속도로 나타나도록 하기 위해서이다.

비록 STS-N 신호가 N개의 STS-1 프레임을 다중화하는 데 사용한다고 보는 것은 오랍르지만 이들 STS-1 프레임들의 페이로드가 하나의 커다란 STS-N 프레임을 구성하기 위해 연결될 수도 있다. 이는 STS-Nc로 명명된다(여기서 c는 접속(concatenate)되어 있다는 의미이다.) 부하로 사용되는 필드 중의 하나는 이와 같은 목적으로 사용된다. 위의 그림은 세 개의 STS-1 프레임이 하나의 STS-3c 프레임으로 접속되는 경우를 도식적으로 나타낸다. 어떤 SONET 링크가 STS-3이 아닌 STS-3c로 지정되는 것의 중요한 의미는 STS-3이 세 개의 51.84Mbps 링크 세 개가 하나의 고아섬유를 공유하는 것으로 간주되는 반면, STS-3c는 링크 사용자에게 155.25Mbps 파이프 한개로 보인다는 점이다.

===== 2-4 오류 검출 =====
때때로 비트 오류가 프레임에 영향을 미친다. 오류는 광섬유에서는 비록 자주 발생하지 않지만, 교정잡업이 수행될 수 있도록 오류를 검출하는 방법이 필요하다. 그렇지 않으면 사용자는 조금 전까지 컴파일이 잘되던 C 프로그램이 네트워크 파일 시스템을 통해 복사를 하고 나면 왜 문법 오류가 발생하는가를 의아해 할 수 밖에 없게 되다.

컴퓨터 시스템에서 비트 오류를 다루는 기술은 데이터를 자기 디스크나 초기 코어 메모리에 저장하기 위해 개발된 Hamming과 Reed/Solomon 코드에서와 같이 1940년대부터 연구되어 왔다. 이 절에서는 네트워킹에서 주로 사용되는 오류 검출 기술 몇 가지를 설명한다.

오류를 검출하는 것은 문제의 일부분에 불과하다. 검출된 오류를 수정하는 것이 필요하다. 메시지를 수신한 쪽에서 오류를 검출했을 대 취할 수 있는 동작에는 크게 두 가지 접근 방법이 있다. 첫째, 송신자에게 메시지가 변질되었다는 것을 알려서 송신자가 메시지의 복사본을 다시 전송할 수 있도록 하는 것이다. 비트 오류가 드물게 발생한다면, 재전송되는 복사본에 오류가 없을 가능성이 매우 높다. 다른 대안으로는 수신자가 메시지가 변질되었더라도 원래의 메시지를 올바르게 재생성할 수 있도록 해 주느 오류 검출 알고리즘을 이용하는 것이다. 이러한 알고리즘은 오류 수정 코드(error-correcting code)를 이용하는데, 이에 관해서는 뒤에서 살펴보기로 한다.

네트워크 분야에서 전송 오류를 검출하는 데 가장 많이 사용하는 기술은 순회 중복 검사(Cyclic Redundancy Check, CRC)로 알려진 기술이다. 두 개의 간단한 방법인 2차원 패리티(two-dimensional parity)와 체크섬(checksum)을 먼저 소개한다. 2차원 패리티는 BISYNC 프로토콜에서 ASCII 문자를 전송할 때 사용되며, 체크섬은 여러 인터넷 프로토콜에서 사용된다.

모든 오류 검출 방법이 갖고 있는 기본적인 개념은 오류가 발생했는지를 결정하는 데 사용될 수 있는 중복 정보를 프레임에 추가하자는 것이다. 극단적인 경우로, 완전히 같은 데이터 두 개를 보내는 것을 생각할 수 있다. 수신자에게 도착한 두 데이터가 같다면, 두 개 모두가 정확한 경우일 가능성이 높다. 두 개가 다르다면 대개 둘 중의 하나에(또는 두 개 모두에) 오류가 들어간 경우이므로, 두 데이터는 버려져야만 한다. 이 방법은 두 가지 이유에서 나쁜 오류 검출 알고리즘이다. 첫째, n비트의 메시지를 보내기 위해 n비트의 중복 메시지를 보낸다는 점이다. 둘재, 많은 오류가 검출되지 않을 수 있다. 예를 들어, 두 메시지의 같은 비트 위치에서 변질이 생기는 오류인 경우 검출되지 못한다.

다행히 이와 같은 간단한 방법보다는 훨씬 좋은 방법이 가능하다. 일반적으로 n비트의 메시지를 위해서는 n보다 훨씬 작은 k(k<<n)비트만의 중복 비트를 보냄으로써 보다 강력한 오류 검출 능력을 제공할 수 있다. 예를 들어, 이더넷에서는 12,000비트(1,500바이트)까지의 데이터를 전송하는 프레임이 오직 32비트 CRC 코드만을 요구하며, CRC-32로 널리 알려진 코드를 사용한다. 이와 같은 코드는 앞으로 살펴보는 바와 같이 거의 대부분의 오류를 찾아낼 수 있다.

추가로 보내는 비트들을 중복이라고 부르는 이유는 이 비트들이 메시지에 새로운 정보를 추가하는 것이 아니기 때문이다. 대신에, 이 비트들은 어떤 잘 알려진 알고리즘을 적용하여 원래의 메시지로부터 직접 구해지는 것이다. 송신자와 수신자 모두 알고리즘이 어떤 것인지 정확히 알고 있다. 송신자는 중복 비트를 만들어내기 위해 메시지에 이 알고리즘을 적용한다. 그리고 메시지와 중복 비트들을 전송한다. 수신자는 수신된 메시지에 같은 알고리즘을 적용한다. 오류가 없다면 송신자와 같은 결과가 나와야만 한다. 수신자는 송신자가 보내온 것과 자신의 결과를 비교하여 만약 같으면, 전송 중에 미시지에는 오류가 발생하지 않았다고(높은 확률로) 결론지을 수 있다. 같지 않다면, 메시지나 중복 비트가 변질된 것이라고 확신할 수 있다. 따라서, 메시지를 버리거나 가능하다면 수정하는 등의 처리작업을 수행하여야 한다.

이들 중복 비트에 대한 용어를 사용할 때 주의할 사항이 있다. 중복 비트들은 일반적으로는 오류 검출 코드(error-detecting codes)라고 불린다. 그러나 코드를 생성하는 알고리즘이 덧셈에 기초를 하고 있는 경우에는 체크섬(checksum)이라고도 불린다. 뒤에서 살펴볼 인터넷 체크섬은 합을 계산하여 오류 검사를 하기 때문에 적절한 이름이라고 할 수 있다. 그러나 '체크섬'이라는 단어가 CRC를 포함한 모든 형태의 오류 검출 코드를 의미하는 것으로 잘못 사용되는 것을 종종 볼 수 있다. 이것은 혼동을 가져올 수 있으므로, '체크섬'이라는 단어는 덧셈을 사용하는 코드에 대해서만 사용하며, 이 절에서 설명한 일반적인 코드를 지칭할 때는 '오류 검출 코드'라는 단어를 사용하는 것이 바람직할 것이다.

====2.4.1 2차원 패리티 ====
2차원 패리티란 이름이 의미하는 그대로이다. '단순' 패리티는 7비트 코드에서 한 바이트에 있는 1의 비트에 패리티 비트를 추가한다. 즉, 홀수 패리티에서는 바이트에 있는 1의 개수를 홀수로 하기 위해, 짝수 패리티에서는 바이트에 있는 1의 개수를 짝수로 하기 위해, 필요하다면 8번째 비트를 1로 설정한다. 반면, 2차원 패리티는 프레임에 포함된 바이트를 뛰어넘어 각 비트 위치에 대해 유사한 계산을 수행한다. 각 바이트에 대한 패리티 비트에 덧붙여, 이 결과를 전체 프레임에 대한 별도의 패리티 바이트로 설정한다. 

====2.4.2 인터넷 체크섬 알고리즘 ====
체크섬은 비록 링크 레벨에서는 사용되지 않지만, CRC나 패리티와 같은 종류의 기능을 제공하므로 여기서 설명하도록 한다. 인터넷 체크섬이 배경으로 하는 개념은 간단하다. 전송되는 모든 데이터를 워드 단위로 더하고, 그합의 결과를 전송하는 것이다. 이 결과를 체크섬이라 한다. 수신자는 수신된 데이터에 대해 같은 계산을 수행하고, 그 결과를 수신된 체크섬과 비교한다. 체크섬 자체를 포함하여 전송된 데이터가 변질되었다면, 결과는 일치하지 않을 것이므로 수신자가 오류가 발생한 것을 알게 된다.

체크섬의 기본 개념은 여러가지로 변형시킬 수 있다. 인터넷 프로토콜이 사용하는 방법을 정확히 설명하면 다음과 같다. 데이터는 16비트 정수의 연속으로서 간주된다. 즉, 데이터는 16비트 1의 보수 연산에 의하여 더해지며, 그 결과에 대한 1의 보수를 구한다. 이 값이 바로 16비트 체크섬 숫자가 된다.

1의 보수 연산에서는 음의 정수 -x는 x의 보수, 즉 x의 각 비트가 반대로 된 수로 표현되다. 1의 보수 연산에서 음의 정수 -x는 x의 보수, 즉 x의 각 비트가 반대로 된 수로 표현된다. 1의 보수 연산에서 수를 더할 때는 최고 자릿수의 캐리는 결과에 더해져야 한다.

다음의 프로그램은 인터넷 체크섬 알고리즘을 평이하게 구현한 예이다. 인수 count는 buf의 길이를 16비트 단위로 넘겨 준다. 프로그램의 루틴은 buf의 길이가 16비트의 정수배가 아니면 이미 16비트의 정수배가 되게 0으로 이미 패딩되어 있다는 것을 가정하고 있다.

<file c cksum.c>
u_short
cksum(u_short *buf, int count)
{
	register u_long sum = 0;
	while(count--)
	{
		sum += *buf++;
		if(sum & 0xFFFF0000)
		{
			/* 캐리가 발생하였으므로 1을 더한다. */
			sum &= 0xFFFF;
			sum++;
		}
	}
	return ~(sum & 0xFFFF);
}
</file>

이 코드는 계산이 보통의 기계에서 수행되는 2의 보수 연산이 아니라 1의 보수 연산을 통해 이루어지고 있다는 점을 확실히 보여 주고 있다. while 루프 안에 if문을 주의 깊에 살펴보라. sum의 위쪽 16비트에 캐리가 있으면 앞의 예에서와 같이 sum을 1만큼 증가시킨다.

앞의 반복 코드와 비교해 볼 때, 이 알고리즘은 작은 수의 중복 비트를 사용하기 때문에 월등하다. 어떤 길이의 메시지라도 16비트의 중복 비트만이 소요된다. 그러나 오류 검출 능력면에서는 썩 훌륭하지 못하다. 에를 들어, 한 쌍의 단일 비트 오류가, 같은 양만큼을 한 워드에서는 증가시키고 다른워드에서는 감소시키는 형태로 발생한다면, 오류는 검출되지 못한다. 이와 같은 알고리즘이 오류에 대해서 약한(예를 들어, CRC와 비교할 떄) 보호를 제공하면서도 사용되는 이유는 간단하다. 소프트웨어로 구현하기가 간단하기 때문이다. ARPANET에서의 경험에 의하면 이 형태의 체크섬이면 충분한 것으로 밝혀졌다. 사실 이것이 충분한 이유는, 이 체크섬은 종단 간의 프로토콜에서 마지막 방어선의 역할을 하며, 대부분의 오류는 CRC와 같은 보다 강력한 링크 계층 오류 검출 알고리즘에 의하여 처리되기 때문이다.

==== 2.4.3 순회 중복 검사 ====
오류 검출 알고리즘의 설계에 있어서 제일 중요한 목적은 작은 수의 중복 비트만을 사용하여 오류 검출의 확률을 극대화하는 것이라는 점은 이제 분명해졌다. 순회 중복 검사(Cyclic Redundancy Check, CRC)는 이와 같은 목적을 달성하기 위해 매우 강력한 수학적 배경을 사용한다. 예를 들어, 32비트 CRC는 수천 바이트 길이의 메시지에서 발생할 수 있는 대개의 비트 오류들에 대해 강력한 보호를 제공한다. CRC의 이론적 근거는 유한 필드라고 불려지는 수학 영역에 그 뿌리를 두고 있다. 

먼저 최상위 항이 X^n 이 되는 n차 다항식으로 표현되는 n+1 비트의 메시지르 생각해보자. 메시지를 다항식으로 표현하는 방법은 메시지의 각 비트의 값을 다항식에서 각항의 상수가 되도록 하는 것이다.

따라서, 이제 송신자와 수신자가 다항식을 서로 교환하는 문제로 바꾸어 생각할 수 있다.

CRC를 계산하기 위해서는 송신자와 수신자가 제수 다항식 C(x)에 동의하여야 한다. C(x)는 k차 항의 다항식이다. 예를 들어, C(x)=X^3+X^2+1이라 가정하자. 이 경우 k=3이다. 'C(X)가 어디서 나온 것이냐?' 라는 질문에 대한 답은 대개 책에 나와 있다이다. 다양한 환경에서 매우 좋은 결과를 제공하는 제수 다항식이 여러 개 존재하며, 그 중 하나를 선택하는 것은 대개 프로토콜 설계의 일부분으로 이루어진다. 예를 들어, 이더넷 표준은 잘 알려진 32차 다항식을 사용한다.

송신자가 메시지 n+1비트 길이 메시지 M(x)을 전송하려고 할 때, 실제로 전송되는 것은 n+1에 k비트를 더한 것이 보내진다. 추가되는 중복 비트를 포함한 전송되는 메시지 전체를 P(x)라 하자. 이제 할 일은 C(x)로 정확히 나누어 떨어지도록 다항식 P(x)를 만드는 방법을 찾아내는 것이다. P(x)를 어떻게 만드는가는 후에 설명한다. P(x)가 링크를 통해 전달되고 전송 중에 오류가 발생하지 않으면, 수신자가 C(x)로 P(x)를 나머지가 0이 되도록 정확히 나눌 수 있어야 한다. 반대로, 전송 중 P(x)에 어떤 오류가 발생하면, 이제는 수신된 다항식이 C(x)로 정확히 나누어 떨어지게 될 가능성은 희박해진다. 결국, 수신자는 0이 아닌 나머지를 얻게 되며, 이는 오류가 발생했다는 것을 의미한다.

  * 모든 다항식 B(x)는 제수 다항식 C(x)에 비해 차수가 높으면 C(x)로 나눌 수 있다.
  * B(x)와 C(x)의 차수가 같으면, 모든 다항식 B(x)는 C(x)로 한번 나눌 수 있다.
  * B(x)가 C(x)에 의하여 나누어질 때, 나머지는 B(x)에서 C(x)를 빼서 얻어진다.
  * B(y)에서 C(x)를 빼는 것은 대응되는 상수 쌍에 대한 배타적 OR(XOR) 연산을 통해 간단히 이루어진다.

===== 2-5 신뢰성 있는 전송 =====
프레임은 전송 중에 변질되며 CRC 같은 오류 코드가 이를 검출하기 위해 사용된다. 어떤 오류 코드는 오류를 수정하기에 충분하도록 강력하기도 하지만, 현실적으로는 가장 뛰어는 오류 수정 코드도 과도한 부하를 부가하지 않으면서 네트워크 링크에서 발생할 수 있는 여러 종류의 비트 및 버스트 오류를 처리할 만큼 발전되어 있지 않다. 따라서 변질된 프레임은 버려져야 한다. 프레임을 신뢰성 있게 전달하려는 링크 레벨 프로토콜은 이와 같은 버려진 프레임을 어떻게든 복구하여야만 한다.

대개의 경우, 신뢰성 있는 전달은 긍정응답(Acknowledgment, ACK)와 타임아웃(time-out)이라는 두가지 기본적인 방법의 조합으로 이루어진다. ACK는 프로토콜이 앞서 보낸 프레임을 받았다고 상대방에게 알리기 위해 되돌려 보내는 작은 제어 프레임이다. 비록 프로토콜에 따라 ACK를 반대방향으로 보낼 데이터 프레임에 피기백(piggyback)할 수도 있지만, 제어 프레임이란 데이터는 포함하지 않고 헤더만 가진 프레임을 의미한다. 송신자가 ACK를 수신하면 프레임이 성공적으로 전달되었다는 것을 알게 된다. 송신자가 적당한 시간 후에도 ACK를 받지 못하면, 원래의 프레임을 재전송한다. 이와 같이 적당한 시간을 기다리는 행위를 타임아웃이라 한다.

신뢰성 있는 전달의 구현을 위해 ACK와 타임아웃을 사용하는 일반적인 정책을 때때로 자동 반복 요구(Automatic Repeat Request, ARQ)라고 한다. 이 절에서는 세 가지의 다른 ARQ 알고리즘을 특정 프로토콜의 헤더 필드에 대한 구체적인 설명은 하지 않는 일반적인 방식으로 설명한다.

==== 2.5.1 정지대기 ====
가장 간단한 ARQ 방식은 정지대기(stop-and-wait) 알고리즘이다. 정지대기의 개념은 단순하다. 송신자는 한 프레임을 전송한 뒤 다음 프레임을 전송하기 전에 ACK를 기다린다는 것이다. 어떤 시간 후까지 ACK가 없으면, 송신자는 타임아웃을 발생시키고 원래의 프레임을 재전송한다.

그림은 위의 알고리즘에서 파생되는 네 가진의 다른 과정을 나타내고 있다. 그림은 프로토콜의 동작을 설명한는 보편적인 방법인 시간 진행 방법을 따르고 있는데, 송신자는 왼쪽에, 수신자는 오른쪽에 있으며, 시간은 위에서 아래로 흐른다. 그림의 (a)는 ACK가 정해진 시간 안에 수신되는 상황을 나타내며, (b)와 (c)는 원래의 프레임과 ACK가 손실되는 상황을 각각 나타낸다. (d)는 타임아웃이 너무 빨리 발생하는 상황이다. 여기서 프레임이 '손실'되었다는 말은 프레임이 전송 중에 변질되고, 그것이 수신자 쪽에서 오류 코드에 의하여 검출되며, 결국 프레임이 버려지는 것을 의미한다.

정지대기에는 한 가지 중요하고 미묘한 사항이 있다. 송신자가 프레임을 보내고 수신자는 그에 대한 ACK를 보냈는데, 이 ACK가 상실되거나 지연되는 상황을 가정하자. 이 상황은 그림의 (c)와 (d)에 표시되어 있다. 두 경우 모두 송신자는 타임아웃을 발생시키고, 원래의 프레임을 재전송한다. 그러나 수신자는 앞의 프레임을 정확히 받았고 ACK도 하였기 때문에 이 프레임을 다음 프레임으로 생각한다. 따라서 하나의 프레임이 중복되어 전달될 위험성이 있다. 이 문제를 해결하기 위해, 정지대기 프로토콜의 헤더는 대개 1비트 순서번호를 포함하며 각 프레임의 순서 번호에는 그림과 같이 0과 1이 교대로 사용된다.

==== 2.5.2 슬라이딩 윈도우 ====
다시 8KB의 지연시간 3 대역폭 값을 갖는 링크와 1KB 길이의 프레임에서의 전송 과정을 생각해보자. 송신자가 첫 번째 프레임의 ACK가 도착하는 순간에 9번째 프레임을 전송할 수 있도록 하는 것이 바람직하다. 이것을 가능하게 해주는 알고리즘을 슬라이딩 윈도우(sliding window)라 하며, 그 시간 진행 표시는 그림에 나타내었다.

=== 슬라이딩 윈도우 알고리즘 ===
슬라이딩 윈도우 알고리즘은 다음과 같이 동작한다. 우선, 송신자는 SeqNum으로 표시되는 순서번호를 각 프레임에 할당한다. 지금은 SeqNum이 유한한 길이의 헤더 필드로 구현된다는 점을 고려하지 않고, 대신 무한대로 증가할 수 있다고 가정하기로 한다. 송신자는 세 개의 변수를 유지한다. SWS로 표시되는 송신 윈도우 크기(send widnow size)는 송신자가 보낼 수 있는 미결된(즉, ACK를 받지 않은) 프레임 수의 상한선을 나타내며, LAR(Last Acknowledgment Receive)은 가장 최근에 수신된 ACK의 순서번호를 나타내며, LFS(Last Frame Sent)는 마지막으로 송신한 프레임의 순서번호를 나타낸다. 송신자는 또 다음과 같은 조건을 유지하며 동작한다.

  LFS-LAR <= SWS
  
ACK가 도착하면, 송신자는 LAR을 오른쪽으로 하나 이동하며, 따라서 하나의 프레임을 더 보내는 것이 가능하다. 또한 송신자는 전송한 각 프레임에 타이머를 부착하고, ACK가 수신되기 전에 타이머가 종료되면 프레임을 재전송한다. 여기서 송신자는 프레임이 응답될 때까지 재전송을 준비하여야 하므로 SWS만큼의 프레임을 버퍼에 저장할 준비를 하여야 한다는 점에 유의하도록 한다.

수신자는 세 개의 변수를 유지한다. RWS로 표시되는 수신 윈도우 크기(receive window size)는 수신자가 받아들이는 프레임 수의 상한선을 나타내며, LAF(Last Acceptable Frame)는 받아들일 수 있는 최대한의 프레임의 순서번호를 나타내며, LFR(Last Frame Received)은 다음에 받을 것으로 예상되는 프레임 중에서 순서번호가 최소인 것을 표시한다. 수신자 또한 다음과 같은 조건을 항상 만족시키며 동작한다.

  LAS-LFR<=RWS


순서번호 SeqNum을 갖는 프레임이 도착하면, 수신자는 다음과 같은 작업을 수행한다. SeqNum <= NFR이거나 SeqNum>LAF 이면, 프레임은 수신자 윈도우의 밖에 해당하므로 버린다. LFR < SeqNum <= LAF 이면, 프레임은 수신자 윈도우에 포함되므로 받아들인다. 다음, 수신자 ACK를 보내야 할지를 결정하여야 한다. 우선 SeqNumToAck가 그보다 작은 순서번호를 갖는 프레임은 모두 수신된 것을 의미하며, ACK를 하지 않은 프레임 중에서 큰 순서번호를 가리키도록 한다. 수신자는 보다 높은 순서번호를 갖는 프레임이 수신되었다 하더라도 SeqNumToAck의 수신에 대해 ACK를 보낸다. 이와 같은 ACK를 누적응답이라 한다. 그런 다음 NFR=SeqNumToAck로 하고, LAF=LFR+RWS로 조정한다.

송신 윈도우의 크기는 어떤 주어진 시간에 얼마나 많은 프레임을 링크에 진행시키려 하는가에 따라 선택된다. SWS는 주어진 지연시간 X 대역폭 곱에 대하여 쉽게 게산된다.

반대로 수신자는 RWS를 임의로 결정할 수 있다. 흔히, RWS=1로 하여 수신자가 순서에 맞지 않는 프레임은 버퍼에 보관하지 않는 경우와, SWS=RWS로 하여 수신자가 송신자가 보낸 어떤 프레임도 버퍼에 보관할 수 있는 경우가 사용된다. SWS보다 많은 프레임이 순서가 바뀌어도 도착하는 것은 불가능하기 때문에 RWS>SWS로 하는 것은 의미가 없다.

=== 유한한 순서번호와 슬라이딩 윈도우 ===
프레임의 순서번호는 실제로는 어떤 유한한 크기의 헤더 필드에 기록된다. 이 점은 다시 같은 순서번호를 갖는 다른 프레임을 구분할 수 있어야 한다는 문제를 야기시킨다. 즉, 가능한 순서번호의 개수가 전송 진행 중인 상태에 있는 프레임의 최대 개수보다 커야만 한다. 

순서번호의 공간(즉, 개수)이 전송 진행 중일 수 있는 프레임의 개수보다 한 개 많다고 가정하자. 즉, MaxSeqNum이 사용 가능한 순서번호의 개수라 할 때, SWS<=MaxSeqNum-1이라고 하자. 이것은 충분한 것일까? 이에 대한 대답은 RWS에 따라 다르다. 만일 RWS=1이면, MaxSeqNum>=SWS+1은 충분하다. 만일 RWS와 SWS가 같다면, MaxSeqNum이 송신 윈도우 크기보다 하나 크다는 것은 충분하지 않다.

송신 윈도우의 크기는 사용가능한 순서번호 개수의 반을 넘어서는 안 된다고 밝혀졌다. 정확히 말해 

  SWS < (MaxSeqNum+1)/2

직관적으로, 이것은 정지대기가 순서번호 0과 1을 교대로 사용하는 것처럼, 슬라이딩 윈도우 프로토콜은 순서번호 공간의 반을 교대로 사용한다는 것을 말한다. 유일한 차이는 양쪽을 교대로 사용하는 대신에 양쪽 사이를 연속적으로 이동한다는 점이다.

이 규칙은 RWS=SWS인 상황에서만 해당된다는 점에 주의하자. RWS와 SWS가 임의의 값을 가지는 경우에도 해당되는 보다 일반적인 규칙을 결정하는 것은 연습문제로 남겨 두기로 한다. 또한 윈도우 크기와 순서번호 공간 사이의 관계는 너무나 당연해서 그냥 지나치기 쉬운 사항인 프레임이 전송 중에 순서가 바귀는 일은 없다는 가정에 의존학 있다는 점에 주의하기 바란다.

=== 슬라이딩 윈도우의 구현 ===
다음에 살펴볼 루틴들은 스라이딩 윈도우 알고리즘의 송신자 및 수신자를 어떻게 구현하는가를 보여주고 있다. 이 루틴들은 슬라이딩 윈도우 프로토콜(Sliding Window Protocol, SWP)이라 하는 프로토콜에서 따온 것이다. 프로토콜 그래프 상에서의 주변 프로토콜들에 상관없게 하기 위해, SWP 바로 위의 프로토콜을 HLP(High-Level Protocol), SWP 바로 밑의 프로토콜을 LINK(Link-Level Protocol)로 통칭하여 부르도록 한다.

먼저 한 쌍의 자료구조를 정의하도록 한다. 첫 번째 프레임 헤더는 매우 간단하다. 헤더는 순서번호(SeqNum)과 응답번호(AckNum)를 포함하며, 프레임이 ACK인지 데이터인지를 표시하는 Flag 필드도 포합한다.

	typedef u_char SwpSeqno;
	typedef struct{
		SwpSeqno SeqNum /* 프레임의 순서 번호 */
		SwpSeqno AckNum /* 수신된 프레임에 대한 Ack */
		u_char Flags; /* 8bit 길이의 플래그 */
	}SwpHdr;

다음, 슬라이딩 윈도우 알고리즘의 상태를 위한 자료구조는 다음과 같다. 프로토콜 송신자의 상태는 이 절의 앞에서 설명한 변수 LAR과 LFS는 물론, 전송은 하였지만 ACK를 받지 못한 프레임을 보관하는 큐(sendQ)를 포함한다. 송신상태는 또한 sendWindowNotFull이라는 계수 세마포어를 포함하는데, 일반적으로 세마포어는 semWait와 semSignal 동작을 지원하는 동기화 프리미티브이다. 모든 semSignal 호출은 세마포어를 1만큼 증가시킨다. 모든 semWait 호출은 세마포어를 1만큼 감소시키며, 만일 감소시킨 값이 0 이하가 되면 호출한 프로세스는 정지한다(suspended). semWait를 호출하는 과정 중에 정지된 프로세스는 충분한 semSignal 동작이 수행되어 세마포어 값이 0보다 커지자마자 재시작(resume)할 수 있다.

프로토콜 수신자에서의 상태는 이 절의 앞에서 설명한 변수 LFR에 1을 더한 NFE(Next Frame Expected)와 순서가 바뀌어 수신된 프레임을 보관하는 큐 (recvQ)를 포함한다. 끝으로, 코드에는 나와 있지 않지만 송신 및 수신 위도우의 크기는 상수 SWS와 RWS로 각각 정의된다.

	typedef struct{
		SwpSeqno LAR; /* 마지막으로 수신된 ack의 순서번호 */
		SwpSeqno LFS; /* 마지막 프레임 전송 */
		Semaphore sendWindowNotFull;
		SwpHdr hdr; /* preinitialized 헤더 */
		struct sendQ_slot{
			Event timeout; /* send-timeout과 연계된 이벤트 */
			Msg msg;
		}sendQ[SWS];
		
		/* 수신쪽 상태 : */
		SwpSeqno NFE; /* 수신이 예상되는 다음 번 프레임의 순서번호 */
		struct recvQ_slot{
			int received; /* 메시지가 정상적으로 수신되었나? */
			Msg msg;
		}recvQ[RWS];
	}SwpState;

SWP의 송신자 쪽은 프로시저 sendSWP에 의하여 구현되다. 이 루틴은 상대적으로 간단하다. 우선 semWait는 이 프로세스가 새로운 프레임을 보내도 될 때까지 블로킹되도록 한다. 계속 진행하는 것이 허용되면, sendSWP는 프레임 헤더에 순서번호를 설정하고, 프레임의 복사본을 전송 큐(sendQ)에 보관하고, 프레임이 ACK를 받지 못할 경우를 대비하여 타임아웃 이벤트를 스케줄한다. 다음, 프레임을 LINK로 지칭한 다음 하위 프로토콜로 보낸다.

주의해서 보아야 할 세부 구현사항은 msgAddHdr 호출 바로 전에 있는 store_swp_hdr이다. 이 루틴은 SWP 헤더(state->hdr)를 가지고 있는 C 구조체를 메시지(hbuf)의 앞에 안전하게 부착할 수 있는 바이트 스트림으로 변환한다. 따로 보이지는 않지만, 이 루틴은 헤더에 있는 각 정수 필드를 네트워크 바이트 순서에 맞게 변환하여야 하며, 컴파일러가 C구조체에 추가시켜 놓은 패딩들이 있으면 이를 제거하여야 한다.

이 루틴의 또 다른 복잡한 점은 semWait와 sendWindowNotFull 세마포어의 사용이다. semWindowNotFull은 초깃값으로 송신자의 윈도우 크기(SWS)를 갖는 카운팅 세마포어이다. 송신자가 프레임을 보낼 때마다 semWait는 이 계숫값을 감소시키며, 그 값이 0이 되면 송신자를 블로킹 시킨다. 한편, ACK를 받을 때마다 deliverSWP에 의해 불리는 semSignal은 이 계수를 증가시키며, 따라서 기다리고 있는 송신자가 있으면 블로킹을 해제시킨다.

	static int
	sendSWP(SwpState *state, Msg *frame){
		struct sendQ_slot *slot;
		hbuf[HLEN];
		
		/* 송신 윈도우에 사용 가능한 공간이 있는지 확인하고 기다린다. */
		semWait(&state->sendWindowNotFull);
		state->hdr.SeqNum = ++state->LFS;
		slot=&state->sendQ[state->hdr.SeqNum % SWS];
		store_swp_hdr(state-.hdr, hbuf);
		msgAddHdr(frame, hbuf, HLEN);
		msgSaveCopy(&slot->msg, frame);
		slot->timeout = evSchedule(swpTimeout, slot, SWP_SEND_TIMEOUT);
		return sendLINK(frame);
	}

SWP의 수신 쪽 코드로 넘어가기 전에 일관성이 부족했던 부분에 대한 추가 설명을 하기로 한다. 지금까지 상위 프로토콜은 send 함수를 호출함으로써 하위 프로토콜의 서비스를 수행시킨다고 설명해 왔다. 따라서 SWP를 통해 메시지를 송신하려는 프로토콜은 send(SWP,packet)를 호출할 것이라고 예측햇을 것이다. 그런데 SWP의 송신 동작을 구현하는 함수는 sendSWP로 정의되어 있고, 첫 번째 인자는 SwpState라는 상태 변수이다. 왜 이런 차이를 보이는 것일까? 그 대답은 send에 대한 포괄적(generic) 호출을 SWP 프로토콜에 대한 구체적 sendSWP로 번역 처리하는 접착(glue)코드를 운영체제가 제공한다는 점에 있다. 접착 코드의 핵심 임무는 send의 첫 번째 인자로부터 sendSWP의 함수 포인터와 SWP가 동작하는 데 필요한 프로토콜 상태 정보에 대한 포인터를 찾아내는 것이다. 이처럼 상위 프로토콜이 포괄적 함수 호출을 통해 간접적으로 하위 프로토콜 함수를 호출하도록 하는 이유는 상위 프로토콜 코드 안에 하위 프로토콜에 관한 정보가 나오는 것을 제한하기 위해서이다. 이러한 원칙을 유지하면, 미래에 프로토콜 그래프 구성을 변경하더라도 쉽게 처리할 수 있다.

이제 deliver 동작에 대한 SWP 프로토콜의 구현인 deliverSWP 프로시저에 대해 살펴보자. 이 루틴은 실제로 두 종류의 도착 메시지를 처리하는데, 하나는 이 노드에서 앞서 보냈던 프레임에 대한 ACK 이며, 다른 하나는 이 노드로 도착한 데이터 프레임이다. 어떤 면에서 이 루틴의 ACK와 관련된 부분은 sendSWP로 구현된 송신자 알고리즘의 대응 부분이라고 볼 수 있다. 도착한 메시지가 ACK인지 데이터 프레임인지는 헤더의 Flag 필드를 검사하여 결정한다. 여기서 제시되는 구현은 ACK를 데이터 프레임에 피기배킹하는것을 지원하지 않는다는 점에 유의하도록 한다.

도착한 프레임이 ACK이면 deliverSWP는 전송 큐(sendQ)에 ACK에 해당하는 슬롯(slot)이 있는지 찾아보고, 그 곳에 저장되어 있던 프레임을 해제하며, 타임아웃 이벤트도 취소한다. ACK가 누적된 것일 수 있으므로, 이 작업은 실제로 순환문으로 수행된다. 이 경우에서 한 가지 주의할 사항은 서브루틴 swpInWindow를 호출하는 부분이다. 뒤에 기술된 이 서브루틴은 ACK된 프레임의 순서번호가 송신자가 현재 수신을 예상하고 ACK의 범위에 포함되는지를 확인한다.

도착된 메시지가 데이터인 경우, deliverSWP는 먼저 msgStripHdr과 load_swp_hdr을 호출하여 프레임으로부터 헤더를 떼어낸다. load_swp_hdr은 앞에서 설명했던 store_swp_hdr에 대응하는 것으로서 바이트 스트링을 SWP 헤더가 담고 있는 C 구조체로 변환한다. 다음, deliverSWP는 swpInWindow를 호출하여 프레임의 순서번호가 예상하던 순서번호 범위에 속하는지를 확인한다. 예상 범위에 속하면, 지금까지 수신한 프레임 중 연속된 것에 대해 순환문을 돌면서 deliverHLP 루틴을 호출하여 상위 프로토콜에 전달한다. 또한 누적 ACK를 송신자에게 적용한다.

<file c deliverSWP.C>
static int
deliverSWP(SwpState state, Msg *frame){
	SwpHdr hdr;
	char *hbuf;
	
	hbuf = msgStripHdr(frame, HLEN);
	load_swp_hdr(&hdr, hbuf);
	if(hdr->Flags & FLAG_ACK_VALID){
		/* ACK를 수신한경우 --- 송신한 작업을 수행 */
		if(swpInWindow(hdr.AckNum, state->LAR +1, state->LFS)){
			do{
				struct sendQ_slot *slot;
				slot = &state->sendQ[++state->LAR % SWS];
				evCancel(slot->timeout);
				msgDestroy(&slot->msg);
				semSignal(&state->sendWindowNotFull);
			}while(state->LAR != hdr.AckNum);
		}
		
		if(hdr.Flags & FLAG_HAS_DATA){
			struct recvQ_slot *slot;
			
			/* 데이터 패킷을 수신한 경우 --- 수신쪽 작업을 수행 */
			slot = &state->recvQ[hdr.SeqNum % RWS];
			if(!swpInWindow(hdr.SeqNum, state->NFE, state->NFE+ RWS - 1)){
				/* 메시지를 버린다 */
				return SUCCESS;
			}
			msgSaveCopy(&slot->msg, frame);
			slot->received = TRUE;
			if(hdr.SeqNum==state->NFE){
				Msg m;
				while(slot->received){
					deliverHLP(&slot->msg);
					msgDestroy(&slot->msg);
					slot->received = FALSE;
					slot = &state->recvQ[++state->NFE % RWS];
				}
				/* ACK를 보낸다. */
				prepare_ack(&m, state->NFE -1);
				sendLINK(&m);
				msgDestroy(&m);
			}
		}
		return SUCCESS
	}
	return pos < maxpos;
}
</file>
=== 프레임 순서와 흐름제어 ===
슬라이딩 윈도우 프로토콜은 아마 컴퓨터 네트워크 분야에서 가장 널리 알려진 알고리즘일 것이다. 그러나 이 알고리즘에서 쉽게 혼동을 일으키는 사항은 이것이 세 개의 다른 역할로 사용될 수 있다는 점이다. 첫 번째 역할은 이 절에서 집중적으로 살펴보았던 것으로 신뢰성 없는 링크를 통해 프레임을 신뢰성 있게 전달하는 것이다. 이것은 이 알고리즘의 핵심 기능이다.

슬라이딩 윈도우 알고리즘의 두 번째 역할은 프레임이 전송되는 순서를 유지하는 것이다. 이것은 수신자에서 쉽게 이루어진다. 각 프레임이 순서번호를 갖고 있기 때문에 수신자는 어떤 순서번호를 갖는 프레임은 그보다 작은 순서번호를 갖는 모든 프레임을 다음 상위 단계 프로토콜에게 건네준 다음에 건네지도록만 하면 된다. 즉, 수신자가 순서를 바뀐 프레임을 상위 단계에게 넘겨 주지 말고 버퍼에 담아 두면 된다. 수신자가 먼저 전달되어야 할 모든 프레임을 기다리지 않고 다음 프로토콜로 프레임을 건네주는 변화된 알고리즘이 있을 수 있지만, 이 절에서 기술된 슬라이딩 윈도우 알고리즘은 프레임의 순서를 유지한다. 여기서 따져 보아야 할 문제는 프레임의 순서를 유지하는 슬라이딩 윈도우 프로토콜이 실제로 필요한 것인지, 아니면 링크 단계에서는 불필요한 기능인지에 관한 것이다.

슬라이딩 윈도우가 가끔씩 수행하는 세 번째 역할은 수신자가 송신자의 전송속도를 조절할 수 있도록 하는 방법인 흐름제어를 지원하는 것이다. 이 방법은 송신자가 수신자를 앞질러 가는 것을 막는, 즉 송신자가 수신자가 처리할 수 있는 것보다 많은 데이터를 전송하는 것을 방지하는데 사용된다. 이것은 대개 수신자가 받은 프레임에 대해 응답을 하는 한편, 얼마나 많은 프레임을 받을 여유가 있는가를 송신자에게 알리도록 슬라이딩 윈도우를 확장하여 구현한다. 수신자가 받을 수 있는 프레임의 개수는 얼마나 많은 버퍼 공간이 있는가에 해당된다. 순서를 맞추어 전달하는 경우와 마찬가지로 흐름제어를 슬라이딩 윈도우 프로토콜에 포함시키기 전에 흐름제어가 링크 단계에서 반드시 필요한가를 고려해 볼 필요가 있다.

